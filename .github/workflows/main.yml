name: Databricks Login & Test (Linux Self-Hosted)

on:
  push:
    branches:
      - main

jobs:
  login_databricks_hvault:
    runs-on: self-hosted

    steps:
      # ðŸ”¹ Paso 0: Checkout del repo
      - name: Checkout
        uses: actions/checkout@v4

      # ðŸ”¹ Paso 1: Login en Vault
      - name: Login en Vault
        shell: bash
        env:
          VAULT_ADDR: http://127.0.0.1:8200
          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }}
          VAULT_SKIP_VERIFY: "true"
          PATH: ${{ env.PATH }}:/home/gha-runner/vault
        run: |
          vault --version
          vault login $VAULT_TOKEN
          vault token lookup

      # ðŸ”¹ Paso 2: Obtener token de Databricks desde Vault
      - name: Obtener token de Databricks
        id: get-creds
        shell: bash
        env:
          VAULT_ADDR: http://127.0.0.1:8200
          VAULT_SKIP_VERIFY: "true"
          PATH: ${{ env.PATH }}:/home/gha-runner/vault
        run: |
          dbToken=$(vault kv get -field=DATABRICKS_TOKEN secret/azure)
          echo "DATABRICKS_TOKEN=$dbToken" >> $GITHUB_OUTPUT

      # ðŸ”¹ Paso 3: Importar notebooks en /Shared/notebook/py
      - name: Importar notebooks en Databricks
        shell: bash
        env:
          DATABRICKS_HOST: "https://adb-3120226433905944.4.azuredatabricks.net"
          DATABRICKS_TOKEN: ${{ steps.get-creds.outputs.DATABRICKS_TOKEN }}
          PATH: ${{ env.PATH }}:~/databricks-env/bin
        run: |
          source ~/databricks-env/bin/activate
          
          # Crear carpeta si no existe
          databricks workspace mkdirs /Shared/notebook/py
          
          for notebook in notebooks/*.py; do
            NOTEBOOK_NAME="${notebook##*/}"   # reemplazo de basename
            echo "Importando $NOTEBOOK_NAME en /Shared/notebook/py..."
            databricks workspace import "$notebook" "/Shared/notebook/py/$NOTEBOOK_NAME" \
              --language PYTHON --overwrite
          done

      # ðŸ”¹ Paso 4: Crear Job Workflow desde JSON
      - name: Crear Job Workflow en Databricks
        shell: bash
        env:
          DATABRICKS_HOST: "https://adb-3120226433905944.4.azuredatabricks.net"
          DATABRICKS_TOKEN: ${{ steps.get-creds.outputs.DATABRICKS_TOKEN }}
          PATH: ${{ env.PATH }}:~/databricks-env/bin
        run: |
          source ~/databricks-env/bin/activate
          
          for job_file in jobs/*.json; do
            echo "Creando job workflow desde $job_file..."
            databricks jobs create --json "$( < "$job_file" )"   # reemplazo de cat
          done
